{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <a href=\"http://www.uc.pt/fctuc/dei/\">\n",
    "    <div style=\"float:left; width: 75%;\">\n",
    "        <img src=\"https://eden.dei.uc.pt/~naml/images_ecos/dei25.png\"/>\n",
    "    </div>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T09:18:55.583235Z",
     "start_time": "2021-01-04T09:18:52.571712Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Just to make plots look better\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['lines.linewidth'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color='#3498db'>Introduction to Machine Learning</font></h2>\n",
    "\n",
    "The main goal of this class is introduce you to the fundamental steps of using Scikit-Learn in Python. To to this we are going to use the [Breast Cancer Wisconsin Diagnostic Database](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data).  \n",
    "\n",
    "The dataset comprises a wide range of details concerning breast cancer tumors, along with classification labels indicating whether they are *malignant* or *benign*. It is composed by 569 instances, each representing a distinct tumor characterised 30 attributes or features, including characteristics like tumor radius, texture, smoothness, and area.\n",
    "\n",
    "Our objective with this dataset is to construct a machine learning model capable of utilizing tumor-related information to make predictions about the malignancy or benign nature of tumors.\n",
    "\n",
    "Scikit-learn provides a collection of preloaded datasets that we can seamlessly import into Python, and the specific dataset we require is readily available. Let's proceed to import and load this dataset.\n",
    "\n",
    "\n",
    "\n",
    "### Variable Description\n",
    "Attribute Information:\n",
    "\n",
    "- ID number \n",
    "- Diagnosis (M = malignant, B = benign) \n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- Radius (mean of distances from center to points on the perimeter) \n",
    "- Texture (standard deviation of gray-scale values) \n",
    "- Perimeter \n",
    "- Area \n",
    "- Smoothness (local variation in radius lengths) \n",
    "- Compactness (perimeter^2 / area - 1.0) \n",
    "- Concavity (severity of concave portions of the contour) \n",
    "- Concave points (number of concave portions of the contour) \n",
    "- Symmetry \n",
    "- Fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
    "13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "# Load dataset\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data` variable serves as a Python object functioning similarly to a dictionary. It is crucial to focus on specific keys within this dictionary, including the names of classification labels (`target_names`), the real labels (`target`), the names of attributes or features (`feature_names`), and the attributes themselves (`data`).\n",
    "\n",
    "Attributes play a pivotal role in any classifier as they encapsulate vital characteristics about the underlying data. In the context of predicting the label we are interested in (distinguishing between malignant and benign tumors), potential informative attributes might encompass tumor size, radius, and texture.\n",
    "\n",
    "Let's proceed to create new variables for each of these essential sets of information and assign the corresponding data to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "0\n",
      "mean radius\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "print(label_names)\n",
    "print(labels[0])\n",
    "print(feature_names[0])\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az the cell above our classes are denoted as `malignant` and `benign` and they are subsequently encoded into binary values: 0 corresponds to malignant tumors, while 1 corresponds to benign tumors. Hence, the initial data instance in our dataset represents a malignant tumor with a mean radius of 1.79900000e+01.\n",
    "\n",
    "With our data successfully loaded and class labels defined, we are now ready to proceed with our machine learning classifier development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing the Data in Training and Test\n",
    "\n",
    "Tto measure the performance of a classifier, it is essential to test the model on data it hasn't seen during training. To accomplish this, it's a common practice to partition your dataset into two distinct ones: a `training set` and a `test set`.\n",
    "\n",
    "The training set is utilized for model development, training, and evaluation. T\n",
    "\n",
    "The test set is reserved for assessing how well the trained model generalizes to unseen data. This methodology provides valuable insights into the model's performance and its ability to handle new, unseen instances.\n",
    "\n",
    "Thankfully, scikit-learn offers a convenient function called \"train_test_split()\" that simplifies the process of dividing your dataset into these distinct sets. You can import this function and then apply it to split your data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split our data\n",
    "##TODO: Your code here!\n",
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the \"train_test_split()\" function, the data is randomly divided, and the degree of the split is controlled by the `test_size` argument. In this instance, split the data by allocating 33% of the initial dataset to the test set (referred to as \"test\"), while the remaining data constitutes the training dataset (referred to as \"train\"). Additionally, we've created corresponding labels for both the training and test datasets, known as \"train_labels\" and \"test_labels.\"\n",
    "\n",
    "With this data preparation step complete, we're now ready to proceed with the training of our initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction and Evaluation\n",
    "Machine learning encompasses a variety of models, and each of these models possesses its unique set of advantages and limitations.\n",
    "\n",
    "We are going to use to instatiate a few algorithms, and see how they performed in the Breast Cancer Wisconsin Diagnostic Database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "##TODO: Your code here!\n",
    "\n",
    "clf_neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_neigh.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the KNeighborsClassifier. Then we initialize the classifier and trained it using the `fit` method.\n",
    "\n",
    "Once our model has been trained, we can use it for making predictions on our test set. This is achieved by employing the `predict()` function, which furnishes an array of predictions for each individual data instance within the test set. Subsequently, we can print these predictions to gain insight into the outcomes generated by the model.\n",
    "\n",
    "To perform predictions on the test set and observe the results, apply the \"predict()\" function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "##TODO: Your code here!\n",
    "preds = clf_neigh.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by output above, the `predict()` function returns an array of 0s and 1s, symbolizing our predicted values for tumor classification (distinguishing between malignant and benign).\n",
    "\n",
    "With our predictions in hand, the next step is to assess the performance of our kNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model Accuracy\n",
    "\n",
    "Taking into account the array of the true class labels, we can assess the accuracy of our model's predictions by conducting a comparison between the two arrays (`test_labels` versus `preds`). To achieve this, we will employ the scikit-learn function \"accuracy_score()\" to compute the accuracy of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score \t= 0.9414893617021277\n",
      "recall score \t= 0.9504132231404959\n",
      "f1 score \t= 0.9543568464730291\n",
      "Confusion Matrix\n",
      " [[ 62   5]\n",
      " [  6 115]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluates model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "##TODO: Your code here!\n",
    "\n",
    "print(\"accuracy score \\t=\", accuracy_score(test_labels, preds))\n",
    "print(\"recall score \\t=\", recall_score(test_labels, preds))\n",
    "print(\"f1 score \\t=\", f1_score(test_labels, preds))\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "##TODO: Your code here!\n",
    "clf_tree = tree.DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=6)\n",
    "clf_tree.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "##TODO: Your code here!\n",
    "preds = clf_tree.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score \t= 0.9627659574468085\n",
      "recall score \t= 0.9752066115702479\n",
      "f1 score \t= 0.9711934156378601\n",
      "Confusion Matrix\n",
      " [[ 63   4]\n",
      " [  3 118]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluates model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "##TODO: Your code here!\n",
    "\n",
    "print(\"accuracy score \\t=\", accuracy_score(test_labels, preds))\n",
    "print(\"recall score \\t=\", recall_score(test_labels, preds))\n",
    "print(\"f1 score \\t=\", f1_score(test_labels, preds))\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "##TODO: Your code here!\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "##TODO: Your code here!\n",
    "preds = clf_svm.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score \t= 0.9521276595744681\n",
      "recall score \t= 0.9917355371900827\n",
      "f1 score \t= 0.963855421686747\n",
      "Confusion Matrix\n",
      " [[ 59   8]\n",
      " [  1 120]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluates model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "##TODO: Your code here!\n",
    "\n",
    "print(\"accuracy score \\t=\", accuracy_score(test_labels, preds))\n",
    "print(\"recall score \\t=\", recall_score(test_labels, preds))\n",
    "print(\"f1 score \\t=\", f1_score(test_labels, preds))\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(test_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conlclude regarding the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
